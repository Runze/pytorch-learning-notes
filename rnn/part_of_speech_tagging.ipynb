{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#example-an-lstm-for-part-of-speech-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Everybody': 5, 'ate': 2, 'apple': 4, 'that': 7, 'read': 6, 'dog': 1, 'book': 8, 'the': 3, 'The': 0}\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {}\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return autograd.Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 0]], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [[word_to_ix[w] for w in s] for s, _ in training_data]\n",
    "inputs = pad_sequences(inputs, maxlen=max([len(s) for s in inputs]), padding='post')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 0, 1],\n",
       "       [1, 2, 0, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = [[tag_to_ix[w] for w in t] for _, t in training_data]\n",
    "targets = pad_sequences(targets, maxlen=max([len(s) for s in outputs]), padding='post')\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Variable(torch.from_numpy(inputs).long())\n",
    "targets = Variable(torch.from_numpy(targets).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 6\n",
    "HIDDEN_SIZE = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedding_size, hidden_size, vocab_size, tagset_size, batch_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.states = self.init_hidden(batch_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_size, target_size)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output, states = self.lstm(self.embedding(input), self.states)\n",
    "        output = self.out(output)\n",
    "        output = F.log_softmax(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        init_hidden_state = Variable(torch.zeros(1, batch_size, self.hidden_size))\n",
    "        init_cell_state = Variable(torch.zeros(1, batch_size, self.hidden_size))\n",
    "        \n",
    "        return (init_hidden_state, init_cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word_to_ix)\n",
    "embedding_size = EMBEDDING_SIZE\n",
    "embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "\n",
    "hidden_size = HIDDEN_SIZE\n",
    "lstm = nn.LSTM(embedding_size, hidden_size, batch_first=True)\n",
    "\n",
    "target_size = len(tag_to_ix)\n",
    "out = nn.Linear(hidden_size, target_size)\n",
    "\n",
    "batch_size = len(inputs)\n",
    "init_hidden_state = Variable(torch.zeros(1, batch_size, hidden_size))\n",
    "init_cell_state = Variable(torch.zeros(1, batch_size, hidden_size))\n",
    "states = (init_hidden_state, init_cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.0125  0.0638 -0.1566  0.0795 -0.0155  0.0252\n",
      "  0.0374  0.0070 -0.1613  0.0325 -0.0805 -0.1018\n",
      " -0.0083 -0.0942 -0.2753  0.0079  0.0361 -0.0752\n",
      "  0.0728 -0.0845 -0.2299  0.1048  0.0292 -0.0769\n",
      "  0.0805  0.0428 -0.1351  0.0395 -0.1368 -0.1728\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.3708  0.2416 -0.1105  0.2070 -0.0066 -0.0789\n",
      " -0.1872  0.2158 -0.2571  0.0726 -0.0335 -0.0738\n",
      " -0.1694  0.2340 -0.2225  0.1150 -0.0497  0.0140\n",
      " -0.4145  0.0822 -0.1314  0.2731 -0.0454 -0.1007\n",
      " -0.1635  0.0525 -0.2342  0.0998 -0.0228 -0.0476\n",
      "[torch.FloatTensor of size 2x5x6]\n",
      "\n",
      "(Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.0805  0.0428 -0.1351  0.0395 -0.1368 -0.1728\n",
      " -0.1635  0.0525 -0.2342  0.0998 -0.0228 -0.0476\n",
      "[torch.FloatTensor of size 1x2x6]\n",
      ", Variable containing:\n",
      "(0 ,.,.) = \n",
      "  0.1139  0.0810 -0.3410  0.0620 -0.2803 -0.3426\n",
      " -0.3066  0.1363 -0.4942  0.3002 -0.0416 -0.0923\n",
      "[torch.FloatTensor of size 1x2x6]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "output, states = lstm(embedding(inputs), states)\n",
    "print(output)\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.0856 -0.3301 -0.1152\n",
      " -0.0453 -0.3505 -0.1871\n",
      "  0.0551 -0.2725 -0.2111\n",
      "  0.0238 -0.3073 -0.1981\n",
      " -0.0626 -0.3845 -0.2050\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.1152 -0.5399 -0.0718\n",
      " -0.0628 -0.3807 -0.1236\n",
      " -0.1161 -0.3860 -0.0832\n",
      " -0.0696 -0.5799 -0.1282\n",
      " -0.0303 -0.3791 -0.1528\n",
      "[torch.FloatTensor of size 2x5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = out(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.6785 -0.5937 -0.7151\n",
      " -0.6844 -0.6782 -0.7254\n",
      " -0.6112 -0.6380 -0.7592\n",
      " -0.6475 -0.5661 -0.7287\n",
      " -0.7094 -0.6958 -0.7196\n",
      "\n",
      "(1 ,.,.) = \n",
      " -0.7080 -0.8035 -0.6717\n",
      " -0.7019 -0.7084 -0.6619\n",
      " -0.7824 -0.7515 -0.6312\n",
      " -0.7409 -0.8387 -0.6588\n",
      " -0.6771 -0.6905 -0.6674\n",
      "[torch.FloatTensor of size 2x5x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = F.log_softmax(output)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMTagger (\n",
       "  (embedding): Embedding(9, 6)\n",
       "  (lstm): LSTM(6, 6, batch_first=True)\n",
       "  (out): Linear (6 -> 3)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_SIZE, HIDDEN_SIZE, len(word_to_ix), len(tag_to_ix), len(inputs))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,.,.) = \n",
       " -0.7125 -0.6804 -0.6590\n",
       " -0.6862 -0.6986 -0.6383\n",
       " -0.6607 -0.7290 -0.6925\n",
       " -0.7017 -0.6689 -0.6946\n",
       " -0.6940 -0.6867 -0.7415\n",
       "\n",
       "(1 ,.,.) = \n",
       " -0.6741 -0.7061 -0.7286\n",
       " -0.7001 -0.6877 -0.7512\n",
       " -0.7267 -0.6585 -0.6938\n",
       " -0.6847 -0.7180 -0.6917\n",
       " -0.6923 -0.6997 -0.6471\n",
       "[torch.FloatTensor of size 2x5x3]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.7125 -0.6804 -0.6590\n",
       "-0.6862 -0.6986 -0.6383\n",
       "-0.6607 -0.7290 -0.6925\n",
       "-0.7017 -0.6689 -0.6946\n",
       "-0.6940 -0.6867 -0.7415\n",
       "-0.6741 -0.7061 -0.7286\n",
       "-0.7001 -0.6877 -0.7512\n",
       "-0.7267 -0.6585 -0.6938\n",
       "-0.6847 -0.7180 -0.6917\n",
       "-0.6923 -0.6997 -0.6471\n",
       "[torch.FloatTensor of size 10x3]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.view(-1, len(tag_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0  1  2  0  1\n",
       " 1  2  0  1  0\n",
       "[torch.LongTensor of size 2x5]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 0\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 0\n",
       " 1\n",
       " 0\n",
       "[torch.LongTensor of size 10]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.7086\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(outputs.view(-1, len(tag_to_ix)), targets.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.7086\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 0\n",
    "\n",
    "for i in range(targets.size(1)):\n",
    "    output = outputs[:, i, :]\n",
    "    target = targets[:, i]\n",
    "    loss += loss_function(output, target) * targets.size(0)\n",
    "\n",
    "loss / (targets.size(0) * targets.size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    model.zero_grad()\n",
    "    model.states = model.init_hidden(len(inputs))\n",
    "    \n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    loss = loss_function(outputs.view(-1, len(tag_to_ix)), targets.view(-1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "(0 ,.,.) = \n",
       "  0\n",
       "  1\n",
       "  1\n",
       "  0\n",
       "  1\n",
       "\n",
       "(1 ,.,.) = \n",
       "  1\n",
       "  2\n",
       "  0\n",
       "  1\n",
       "  0\n",
       "[torch.LongTensor of size 2x5x1]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inputs).data.topk(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
